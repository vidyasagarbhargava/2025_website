---
title: "Statistics"
format:
  html:
    code-fold: true
execute:
  echo: false
jupyter: python3
---


1. Descriptive Statistics

	•	Measures of Central Tendency: Mean, median, and mode, along with when each is appropriate.
	•	Measures of Dispersion: Range, variance, standard deviation, and interquartile range.
	•	Data Distribution: Understanding normal, binomial, Poisson, and exponential distributions.




```{python}
# import altair with an abbreviated alias
import altair as alt
import pandas as pd
import numpy as np

np.random.seed(42)
columns = ["A", "B", "C"]
source = pd.DataFrame(
    np.cumsum(np.random.randn(100, 3), 0).round(2),
    columns=columns, index=pd.RangeIndex(100, name="x")
)
source = source.reset_index().melt("x", var_name="category", value_name="y")

# Create a selection that chooses the nearest point & selects based on x-value
nearest = alt.selection_point(nearest=True, on="pointerover",
                              fields=["x"], empty=False)

# The basic line
line = alt.Chart(source).mark_line(interpolate="basis").encode(
    x="x:Q",
    y="y:Q",
    color="category:N"
)

# Transparent selectors across the chart. This is what tells us
# the x-value of the cursor
selectors = alt.Chart(source).mark_point().encode(
    x="x:Q",
    opacity=alt.value(0),
).add_params(
    nearest
)

# Draw points on the line, and highlight based on selection
points = line.mark_point().encode(
    opacity=alt.condition(nearest, alt.value(1), alt.value(0))
)

# Draw text labels near the points, and highlight based on selection
text = line.mark_text(align="left", dx=5, dy=-5).encode(
    text=alt.condition(nearest, "y:Q", alt.value(" "))
)

# Draw a rule at the location of the selection
rules = alt.Chart(source).mark_rule(color="gray").encode(
    x="x:Q",
).transform_filter(
    nearest
)

# Put the five layers into a chart and bind the data
alt.layer(
    line, selectors, points, rules, text
).properties(
    width=950, height=300
)
   
```


2. Probability and Probability Distributions

	•	Basic Probability: Concepts of independence, conditional probability, Bayes’ theorem, and the law of total probability.
	•	Random Variables and Probability Distributions: Familiarity with discrete (binomial, Poisson) and continuous (normal, exponential, chi-square) distributions.
	•	Central Limit Theorem: Understanding its implications for sampling and population estimates.

3. Hypothesis Testing and Statistical Inference

	•	Hypothesis Testing: Null and alternative hypotheses, p-values, statistical significance, and confidence levels.
	•	Types of Errors: Type I (false positive) and Type II (false negative) errors.
	•	Confidence Intervals: Construction and interpretation, including confidence levels and margin of error.
	•	ANOVA and T-Tests: For comparing means across groups (independent, paired, one-way ANOVA, two-way ANOVA).

4. Regression Analysis

	•	Linear Regression: Assumptions, interpretation of coefficients, R-squared, and understanding residuals.
	•	Logistic Regression: For binary classification, interpretation of coefficients in terms of odds ratios.
	•	Regularization Techniques: Ridge, Lasso, and Elastic Net to prevent overfitting in high-dimensional datasets.
	•	Multicollinearity: Detecting and addressing multicollinearity issues.

5. Multivariate Statistics

	•	Principal Component Analysis (PCA): Reducing dimensionality and interpreting principal components.
	•	Factor Analysis: Understanding latent factors in data.
	•	Clustering: K-means, hierarchical clustering, and DBSCAN for unsupervised learning.
	•	MANOVA: Multi-way analysis of variance for multivariate response data.

6. Time Series Analysis

	•	Stationarity: Identifying and transforming non-stationary series.
	•	ARIMA Models: Autoregressive, Integrated, Moving Average models for forecasting.
	•	Seasonality and Trend Analysis: Decomposing series into trend, seasonality, and residual components.
	•	Exponential Smoothing: For handling seasonal and trend components in time series.

7. Bayesian Statistics

	•	Bayesian Inference: Understanding prior, likelihood, posterior distributions, and Bayes’ theorem applications.
	•	Markov Chain Monte Carlo (MCMC): Sampling methods, especially when working with complex posterior distributions.
	•	Bayesian Networks: Directed acyclic graphs for representing probabilistic relationships.

8. Statistical Quality Control and Experimental Design

	•	A/B Testing: Setting up, running, and interpreting results; understanding concepts like lift, conversion rates, and sample size calculation.
	•	Design of Experiments (DOE): Full factorial, fractional factorial, and randomized block designs.
	•	Chi-Square Tests: For independence and goodness of fit, especially useful with categorical data.

9. Resampling Methods

	•	Bootstrap Methods: For estimating confidence intervals and understanding distributional properties without strong parametric assumptions.
	•	Jackknife Resampling: Used primarily to estimate bias and variance, especially in small samples.

10. Advanced Topics

	•	Survival Analysis: Kaplan-Meier estimator, Cox proportional hazards model for time-to-event data.
	•	Monte Carlo Simulation: For probabilistic risk analysis and scenario testing.
	•	Hidden Markov Models (HMM): Modeling sequences and state transitions in data, useful for time-series and sequential analysis.